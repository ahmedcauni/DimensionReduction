## Dimension Reduction
Two dimensional reduction techniques on the Mnist dataset
The two techniques I used which I searched for in dimensional reduction are LDA and PCA.

LDA (Linear Discriminant Analysis) is a supervised machine learning algorithm that aims to
reduce the dimensionality of the data while preserving the class separability. The algorithm
achieves this by finding a linear combination of input features that maximizes the distance
between different classes and minimizes the distance within the same class. LDA can be used
for feature extraction and data visualization.

PCA (Principal Component Analysis), on the other hand, is an unsupervised machine learning
algorithm used for dimensionality reduction. PCA aims to find a new set of variables that capture
the most important information in the original data. This is done by projecting the data onto a
new coordinate system in which the new variables are orthogonal (uncorrelated) and capture
the maximum amount of variance in the data. PCA can be used for feature extraction, data
compression, and data visualization.

Achieved an accuracy of almost 92% for LDA and achieved an accuracy of 97% for PCA 

References
-Hastie, T., Tibshirani, R., & Friedman, J. (2009). The elements of statistical learning: data
mining, inference, and prediction. Springer Science & Business Media.
-Duda, R. O., Hart, P. E., & Stork, D. G. (2012). Pattern classification. John Wiley & Sons.
-Jolliffe, I. (2011). Principal component analysis. Springer.
-Shlens, J. (2014). A tutorial on principal component analysis. arXiv preprint arXiv:1404.1100
